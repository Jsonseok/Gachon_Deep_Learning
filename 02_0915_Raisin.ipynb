{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "Z9ZNZXkaTecu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "from keras.optimizers import SGD,Adam\n",
        "from keras import models,layers,metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oh7i8KlOT3sy"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_excel('/content/Raisin_Dataset.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN"
      ],
      "metadata": {
        "id": "b4mbE6x-aSWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aoAEt4zT7HU",
        "outputId": "a7be02b4-e1d8-4db1-f927-d6a74b02aa24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 900 entries, 0 to 899\n",
            "Data columns (total 8 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   Area             900 non-null    int64  \n",
            " 1   MajorAxisLength  900 non-null    float64\n",
            " 2   MinorAxisLength  900 non-null    float64\n",
            " 3   Eccentricity     900 non-null    float64\n",
            " 4   ConvexArea       900 non-null    int64  \n",
            " 5   Extent           900 non-null    float64\n",
            " 6   Perimeter        900 non-null    float64\n",
            " 7   Class            900 non-null    object \n",
            "dtypes: float64(5), int64(2), object(1)\n",
            "memory usage: 56.4+ KB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKLjqpIcvqZf"
      },
      "outputs": [],
      "source": [
        "X = train_df.drop('Class', axis = 1)\n",
        "\n",
        "y = train_df['Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eiKOH_rtP_Q"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "y_1 = encoder.fit_transform(y)\n",
        "X_1 = scaler.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_1,y_1, test_size =0.2 , random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKAwl5t9vzX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb61d8da-eeb0-4a26-9ac1-f494b13aa193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 1s 14ms/step - loss: 0.6813 - accuracy: 0.5083 - val_loss: 0.6714 - val_accuracy: 0.4778\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6580 - accuracy: 0.5333 - val_loss: 0.6410 - val_accuracy: 0.5778\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6160 - accuracy: 0.6361 - val_loss: 0.5843 - val_accuracy: 0.7278\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5671 - accuracy: 0.7264 - val_loss: 0.5340 - val_accuracy: 0.8556\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.8056 - val_loss: 0.4878 - val_accuracy: 0.8444\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4825 - accuracy: 0.8278 - val_loss: 0.4524 - val_accuracy: 0.8556\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.8319 - val_loss: 0.4163 - val_accuracy: 0.8667\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8556 - val_loss: 0.3908 - val_accuracy: 0.8611\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8375 - val_loss: 0.3727 - val_accuracy: 0.8556\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8472 - val_loss: 0.3539 - val_accuracy: 0.8611\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8569 - val_loss: 0.3500 - val_accuracy: 0.8556\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8500 - val_loss: 0.3516 - val_accuracy: 0.8611\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8444 - val_loss: 0.3487 - val_accuracy: 0.8722\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8514 - val_loss: 0.3484 - val_accuracy: 0.8722\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3743 - accuracy: 0.8431 - val_loss: 0.3481 - val_accuracy: 0.8611\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8625 - val_loss: 0.3462 - val_accuracy: 0.8556\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8500 - val_loss: 0.3455 - val_accuracy: 0.8611\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3630 - accuracy: 0.8653 - val_loss: 0.3507 - val_accuracy: 0.8722\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3603 - accuracy: 0.8597 - val_loss: 0.3509 - val_accuracy: 0.8778\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3561 - accuracy: 0.8597 - val_loss: 0.3480 - val_accuracy: 0.8333\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8542 - val_loss: 0.3492 - val_accuracy: 0.8722\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8583 - val_loss: 0.3560 - val_accuracy: 0.8667\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3629 - accuracy: 0.8625 - val_loss: 0.3600 - val_accuracy: 0.8611\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3736 - accuracy: 0.8444 - val_loss: 0.3468 - val_accuracy: 0.8611\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8625 - val_loss: 0.3466 - val_accuracy: 0.8667\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8639 - val_loss: 0.3458 - val_accuracy: 0.8500\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8583 - val_loss: 0.3493 - val_accuracy: 0.8778\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8556 - val_loss: 0.3448 - val_accuracy: 0.8667\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3569 - accuracy: 0.8583 - val_loss: 0.3501 - val_accuracy: 0.8778\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8556 - val_loss: 0.3451 - val_accuracy: 0.8500\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8625 - val_loss: 0.3454 - val_accuracy: 0.8500\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3433 - accuracy: 0.8681 - val_loss: 0.3487 - val_accuracy: 0.8778\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.3544 - accuracy: 0.8639 - val_loss: 0.3443 - val_accuracy: 0.8778\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 0.3605 - accuracy: 0.8625 - val_loss: 0.3449 - val_accuracy: 0.8667\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 1s 23ms/step - loss: 0.3571 - accuracy: 0.8694 - val_loss: 0.3494 - val_accuracy: 0.8778\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3483 - accuracy: 0.8750 - val_loss: 0.3462 - val_accuracy: 0.8611\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 20ms/step - loss: 0.3499 - accuracy: 0.8597 - val_loss: 0.3520 - val_accuracy: 0.8778\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.3613 - accuracy: 0.8625 - val_loss: 0.3469 - val_accuracy: 0.8778\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8694 - val_loss: 0.3417 - val_accuracy: 0.8722\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3566 - accuracy: 0.8653 - val_loss: 0.3424 - val_accuracy: 0.8556\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3401 - accuracy: 0.8597 - val_loss: 0.3431 - val_accuracy: 0.8833\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8694 - val_loss: 0.3423 - val_accuracy: 0.8833\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8653 - val_loss: 0.3428 - val_accuracy: 0.8833\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3477 - accuracy: 0.8667 - val_loss: 0.3424 - val_accuracy: 0.8667\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8667 - val_loss: 0.3486 - val_accuracy: 0.8778\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8750 - val_loss: 0.3417 - val_accuracy: 0.8722\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3474 - accuracy: 0.8681 - val_loss: 0.3450 - val_accuracy: 0.8778\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8639 - val_loss: 0.3460 - val_accuracy: 0.8778\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8653 - val_loss: 0.3478 - val_accuracy: 0.8778\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.8597 - val_loss: 0.3444 - val_accuracy: 0.8722\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3400 - accuracy: 0.8722 - val_loss: 0.3425 - val_accuracy: 0.8722\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3581 - accuracy: 0.8583 - val_loss: 0.3450 - val_accuracy: 0.8778\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8653 - val_loss: 0.3442 - val_accuracy: 0.8667\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3426 - accuracy: 0.8597 - val_loss: 0.3462 - val_accuracy: 0.8778\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3514 - accuracy: 0.8556 - val_loss: 0.3475 - val_accuracy: 0.8722\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8778 - val_loss: 0.3466 - val_accuracy: 0.8722\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3505 - accuracy: 0.8681 - val_loss: 0.3500 - val_accuracy: 0.8778\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8653 - val_loss: 0.3460 - val_accuracy: 0.8667\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8653 - val_loss: 0.3487 - val_accuracy: 0.8778\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.8667 - val_loss: 0.3500 - val_accuracy: 0.8778\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.3366 - accuracy: 0.8681 - val_loss: 0.3463 - val_accuracy: 0.8667\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3391 - accuracy: 0.8708 - val_loss: 0.3427 - val_accuracy: 0.8611\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3436 - accuracy: 0.8708 - val_loss: 0.3417 - val_accuracy: 0.8722\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3376 - accuracy: 0.8708 - val_loss: 0.3436 - val_accuracy: 0.8778\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3344 - accuracy: 0.8736 - val_loss: 0.3444 - val_accuracy: 0.8722\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 12ms/step - loss: 0.3357 - accuracy: 0.8750 - val_loss: 0.3517 - val_accuracy: 0.8278\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3350 - accuracy: 0.8722 - val_loss: 0.3454 - val_accuracy: 0.8667\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3420 - accuracy: 0.8667 - val_loss: 0.3458 - val_accuracy: 0.8778\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3266 - accuracy: 0.8722 - val_loss: 0.3450 - val_accuracy: 0.8722\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8625 - val_loss: 0.3474 - val_accuracy: 0.8778\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3409 - accuracy: 0.8708 - val_loss: 0.3462 - val_accuracy: 0.8389\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8694 - val_loss: 0.3619 - val_accuracy: 0.8611\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8736 - val_loss: 0.3415 - val_accuracy: 0.8667\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8722 - val_loss: 0.3441 - val_accuracy: 0.8722\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8722 - val_loss: 0.3446 - val_accuracy: 0.8722\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8653 - val_loss: 0.3459 - val_accuracy: 0.8500\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8694 - val_loss: 0.3499 - val_accuracy: 0.8722\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8708 - val_loss: 0.3445 - val_accuracy: 0.8778\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3257 - accuracy: 0.8681 - val_loss: 0.3437 - val_accuracy: 0.8667\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8653 - val_loss: 0.3454 - val_accuracy: 0.8667\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8708 - val_loss: 0.3454 - val_accuracy: 0.8667\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8681 - val_loss: 0.3490 - val_accuracy: 0.8778\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8681 - val_loss: 0.3455 - val_accuracy: 0.8667\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8694 - val_loss: 0.3407 - val_accuracy: 0.8667\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8708 - val_loss: 0.3434 - val_accuracy: 0.8667\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8694 - val_loss: 0.3446 - val_accuracy: 0.8667\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8681 - val_loss: 0.3446 - val_accuracy: 0.8722\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.8750 - val_loss: 0.3440 - val_accuracy: 0.8667\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3213 - accuracy: 0.8708 - val_loss: 0.3419 - val_accuracy: 0.8611\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3240 - accuracy: 0.8722 - val_loss: 0.3501 - val_accuracy: 0.8667\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.8667 - val_loss: 0.3436 - val_accuracy: 0.8444\n"
          ]
        }
      ],
      "source": [
        "epoch = 200\n",
        "batch_size = 32\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=50)\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu',  input_shape=(7,) ),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu', ),\n",
        "    Dropout(0.2),\n",
        "    Dense(10, activation='relu', ),\n",
        "    Dense(1, activation='sigmoid', ),\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "mm = model.fit(X_train,y_train,epochs = epoch,batch_size=batch_size,validation_data=(X_test, y_test), callbacks= [es])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_class = [round(x[0]) for x in y_pred]\n",
        "\n",
        "print(accuracy_score(y_pred_class, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ULVAJq0RpBK",
        "outputId": "d904430d-cb74-4c73-ab68-69ae795c990b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step\n",
            "0.8444444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F1_Score"
      ],
      "metadata": {
        "id": "GIpdl7JKaXhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1_score(y_test, y_pred_class))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hkgjq_EUWo1",
        "outputId": "74ab3f60-fa28-450d-a714-3df2fa669d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8556701030927835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TS6hPeATXw39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vUfTILWsXwyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "4ptzLyHDaawx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop('Class', axis = 1).to_numpy()\n",
        "\n",
        "y = train_df['Class']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "y_1 = encoder.fit_transform(y)\n",
        "X_1 = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "b2X_JOSZXc9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_2 = X_1.reshape((X.shape[0], X.shape[1], 1))"
      ],
      "metadata": {
        "id": "guq8kU8jWg5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_2,y_1, test_size =0.2 , random_state= 42)"
      ],
      "metadata": {
        "id": "5ad2x6vUWgy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 200\n",
        "batch_size = 32\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=50)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "_A9AbltdUaJB"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=32, callbacks = es)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho2Y0VTMU10f",
        "outputId": "689a0db7-cab0-463e-e8d7-d14232fc7969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "23/23 [==============================] - 2s 24ms/step - loss: 7.5669 - accuracy: 0.5056 - val_loss: 7.1361 - val_accuracy: 0.4778\n",
            "Epoch 2/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 1.8640 - accuracy: 0.5056 - val_loss: 0.8047 - val_accuracy: 0.4778\n",
            "Epoch 3/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7364 - accuracy: 0.4986 - val_loss: 0.6998 - val_accuracy: 0.5278\n",
            "Epoch 4/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.6895 - accuracy: 0.5319 - val_loss: 0.6519 - val_accuracy: 0.5611\n",
            "Epoch 5/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.6278 - accuracy: 0.6181 - val_loss: 0.5776 - val_accuracy: 0.8056\n",
            "Epoch 6/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5518 - accuracy: 0.7431 - val_loss: 0.5028 - val_accuracy: 0.8500\n",
            "Epoch 7/150\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.5211 - accuracy: 0.7639 - val_loss: 0.4319 - val_accuracy: 0.8167\n",
            "Epoch 8/150\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4732 - accuracy: 0.8125 - val_loss: 0.3996 - val_accuracy: 0.8500\n",
            "Epoch 9/150\n",
            "23/23 [==============================] - 0s 13ms/step - loss: 0.5586 - accuracy: 0.8208 - val_loss: 0.3731 - val_accuracy: 0.8278\n",
            "Epoch 10/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.4847 - accuracy: 0.8375 - val_loss: 0.3691 - val_accuracy: 0.8611\n",
            "Epoch 11/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.9414 - accuracy: 0.8000 - val_loss: 3.0221 - val_accuracy: 0.6333\n",
            "Epoch 12/150\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 2.4391 - accuracy: 0.6319 - val_loss: 0.6916 - val_accuracy: 0.6556\n",
            "Epoch 13/150\n",
            "23/23 [==============================] - 0s 14ms/step - loss: 0.7049 - accuracy: 0.6958 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
            "Epoch 14/150\n",
            "23/23 [==============================] - 0s 21ms/step - loss: 0.5552 - accuracy: 0.7389 - val_loss: 0.5005 - val_accuracy: 0.8056\n",
            "Epoch 15/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.5546 - accuracy: 0.7361 - val_loss: 0.4916 - val_accuracy: 0.8000\n",
            "Epoch 16/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5211 - accuracy: 0.7569 - val_loss: 0.4872 - val_accuracy: 0.7944\n",
            "Epoch 17/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5154 - accuracy: 0.7625 - val_loss: 0.4808 - val_accuracy: 0.8000\n",
            "Epoch 18/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.7917 - val_loss: 0.4740 - val_accuracy: 0.7944\n",
            "Epoch 19/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5208 - accuracy: 0.7792 - val_loss: 0.4659 - val_accuracy: 0.8056\n",
            "Epoch 20/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7750 - val_loss: 0.4540 - val_accuracy: 0.8056\n",
            "Epoch 21/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4913 - accuracy: 0.7861 - val_loss: 0.4415 - val_accuracy: 0.8167\n",
            "Epoch 22/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.8056 - val_loss: 0.4275 - val_accuracy: 0.8167\n",
            "Epoch 23/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.8000 - val_loss: 0.4218 - val_accuracy: 0.8444\n",
            "Epoch 24/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.8222 - val_loss: 0.4028 - val_accuracy: 0.8278\n",
            "Epoch 25/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.8194 - val_loss: 0.3927 - val_accuracy: 0.8278\n",
            "Epoch 26/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.8389 - val_loss: 0.3798 - val_accuracy: 0.8389\n",
            "Epoch 27/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.8486 - val_loss: 0.3793 - val_accuracy: 0.8556\n",
            "Epoch 28/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4545 - accuracy: 0.8347 - val_loss: 0.3692 - val_accuracy: 0.8556\n",
            "Epoch 29/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.8319 - val_loss: 0.3744 - val_accuracy: 0.8611\n",
            "Epoch 30/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.8306 - val_loss: 0.3747 - val_accuracy: 0.8611\n",
            "Epoch 31/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8292 - val_loss: 0.3800 - val_accuracy: 0.8722\n",
            "Epoch 32/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4271 - accuracy: 0.8389 - val_loss: 0.3664 - val_accuracy: 0.8611\n",
            "Epoch 33/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8486 - val_loss: 0.3612 - val_accuracy: 0.8611\n",
            "Epoch 34/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.8389 - val_loss: 0.3577 - val_accuracy: 0.8556\n",
            "Epoch 35/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.8417 - val_loss: 0.5004 - val_accuracy: 0.7389\n",
            "Epoch 36/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5642 - accuracy: 0.7278 - val_loss: 0.4575 - val_accuracy: 0.8167\n",
            "Epoch 37/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4928 - accuracy: 0.7917 - val_loss: 0.4135 - val_accuracy: 0.8722\n",
            "Epoch 38/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.8278 - val_loss: 0.3922 - val_accuracy: 0.8667\n",
            "Epoch 39/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8319 - val_loss: 0.3803 - val_accuracy: 0.8611\n",
            "Epoch 40/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8417 - val_loss: 0.3956 - val_accuracy: 0.8722\n",
            "Epoch 41/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4814 - accuracy: 0.8306 - val_loss: 0.3938 - val_accuracy: 0.8722\n",
            "Epoch 42/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.8347 - val_loss: 0.3844 - val_accuracy: 0.8111\n",
            "Epoch 43/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.8486 - val_loss: 0.3752 - val_accuracy: 0.8444\n",
            "Epoch 44/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.8597 - val_loss: 0.3667 - val_accuracy: 0.8611\n",
            "Epoch 45/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.8486 - val_loss: 0.3664 - val_accuracy: 0.8611\n",
            "Epoch 46/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.8403 - val_loss: 0.3605 - val_accuracy: 0.8611\n",
            "Epoch 47/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.8431 - val_loss: 0.3535 - val_accuracy: 0.8333\n",
            "Epoch 48/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8458 - val_loss: 0.3604 - val_accuracy: 0.8611\n",
            "Epoch 49/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.8569 - val_loss: 0.3555 - val_accuracy: 0.8611\n",
            "Epoch 50/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.8708 - val_loss: 0.3534 - val_accuracy: 0.8667\n",
            "Epoch 51/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8653 - val_loss: 0.3580 - val_accuracy: 0.8667\n",
            "Epoch 52/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.8611 - val_loss: 0.3500 - val_accuracy: 0.8611\n",
            "Epoch 53/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.7306 - val_loss: 0.7155 - val_accuracy: 0.6056\n",
            "Epoch 54/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6092 - accuracy: 0.6944 - val_loss: 0.4431 - val_accuracy: 0.8389\n",
            "Epoch 55/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8222 - val_loss: 0.3928 - val_accuracy: 0.8722\n",
            "Epoch 56/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8375 - val_loss: 0.3735 - val_accuracy: 0.8667\n",
            "Epoch 57/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.8458 - val_loss: 0.3692 - val_accuracy: 0.8667\n",
            "Epoch 58/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8556 - val_loss: 0.3637 - val_accuracy: 0.8667\n",
            "Epoch 59/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8417 - val_loss: 0.3519 - val_accuracy: 0.8667\n",
            "Epoch 60/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.8597 - val_loss: 0.3460 - val_accuracy: 0.8667\n",
            "Epoch 61/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.8569 - val_loss: 0.3478 - val_accuracy: 0.8667\n",
            "Epoch 62/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8542 - val_loss: 0.3432 - val_accuracy: 0.8611\n",
            "Epoch 63/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.8583 - val_loss: 0.3397 - val_accuracy: 0.8611\n",
            "Epoch 64/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8458 - val_loss: 0.3609 - val_accuracy: 0.8778\n",
            "Epoch 65/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.8514 - val_loss: 0.3489 - val_accuracy: 0.8611\n",
            "Epoch 66/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8583 - val_loss: 0.3456 - val_accuracy: 0.8611\n",
            "Epoch 67/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.8625 - val_loss: 0.3413 - val_accuracy: 0.8556\n",
            "Epoch 68/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.8625 - val_loss: 0.3371 - val_accuracy: 0.8667\n",
            "Epoch 69/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.8639 - val_loss: 0.3586 - val_accuracy: 0.8778\n",
            "Epoch 70/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.8611 - val_loss: 0.3401 - val_accuracy: 0.8556\n",
            "Epoch 71/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.8569 - val_loss: 0.3404 - val_accuracy: 0.8667\n",
            "Epoch 72/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.8569 - val_loss: 0.3378 - val_accuracy: 0.8667\n",
            "Epoch 73/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.8681 - val_loss: 0.3435 - val_accuracy: 0.8667\n",
            "Epoch 74/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.8667 - val_loss: 0.3389 - val_accuracy: 0.8611\n",
            "Epoch 75/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.8542 - val_loss: 0.3753 - val_accuracy: 0.8722\n",
            "Epoch 76/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8556 - val_loss: 0.3510 - val_accuracy: 0.8278\n",
            "Epoch 77/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.8514 - val_loss: 0.3565 - val_accuracy: 0.8667\n",
            "Epoch 78/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8597 - val_loss: 0.3505 - val_accuracy: 0.8611\n",
            "Epoch 79/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8639 - val_loss: 0.3483 - val_accuracy: 0.8611\n",
            "Epoch 80/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8653 - val_loss: 0.3464 - val_accuracy: 0.8611\n",
            "Epoch 81/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.8639 - val_loss: 0.3438 - val_accuracy: 0.8556\n",
            "Epoch 82/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8556 - val_loss: 0.3432 - val_accuracy: 0.8611\n",
            "Epoch 83/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.8264 - val_loss: 0.4615 - val_accuracy: 0.8111\n",
            "Epoch 84/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4920 - accuracy: 0.7833 - val_loss: 0.4114 - val_accuracy: 0.8667\n",
            "Epoch 85/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8556 - val_loss: 0.3736 - val_accuracy: 0.8444\n",
            "Epoch 86/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.8458 - val_loss: 0.3612 - val_accuracy: 0.8556\n",
            "Epoch 87/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8500 - val_loss: 0.3560 - val_accuracy: 0.8778\n",
            "Epoch 88/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8583 - val_loss: 0.3541 - val_accuracy: 0.8778\n",
            "Epoch 89/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.8611 - val_loss: 0.3540 - val_accuracy: 0.8722\n",
            "Epoch 90/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.8500 - val_loss: 0.3492 - val_accuracy: 0.8722\n",
            "Epoch 91/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.8542 - val_loss: 0.3638 - val_accuracy: 0.8778\n",
            "Epoch 92/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.8528 - val_loss: 0.3457 - val_accuracy: 0.8333\n",
            "Epoch 93/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8583 - val_loss: 0.3510 - val_accuracy: 0.8556\n",
            "Epoch 94/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8625 - val_loss: 0.3609 - val_accuracy: 0.8722\n",
            "Epoch 95/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8625 - val_loss: 0.3416 - val_accuracy: 0.8278\n",
            "Epoch 96/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8319 - val_loss: 0.3570 - val_accuracy: 0.8278\n",
            "Epoch 97/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8708 - val_loss: 0.3668 - val_accuracy: 0.8667\n",
            "Epoch 98/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8444 - val_loss: 0.3460 - val_accuracy: 0.8611\n",
            "Epoch 99/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.8597 - val_loss: 0.3383 - val_accuracy: 0.8333\n",
            "Epoch 100/150\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8611 - val_loss: 0.3446 - val_accuracy: 0.8611\n",
            "Epoch 101/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8681 - val_loss: 0.3410 - val_accuracy: 0.8556\n",
            "Epoch 102/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4175 - accuracy: 0.8639 - val_loss: 0.3428 - val_accuracy: 0.8556\n",
            "Epoch 103/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.8611 - val_loss: 0.3363 - val_accuracy: 0.8500\n",
            "Epoch 104/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4425 - accuracy: 0.8625 - val_loss: 0.4311 - val_accuracy: 0.8722\n",
            "Epoch 105/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.8611 - val_loss: 0.3378 - val_accuracy: 0.8278\n",
            "Epoch 106/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.8639 - val_loss: 0.3410 - val_accuracy: 0.8611\n",
            "Epoch 107/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8681 - val_loss: 0.3658 - val_accuracy: 0.8667\n",
            "Epoch 108/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4258 - accuracy: 0.8583 - val_loss: 0.3446 - val_accuracy: 0.8611\n",
            "Epoch 109/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4545 - accuracy: 0.8722 - val_loss: 0.3396 - val_accuracy: 0.8611\n",
            "Epoch 110/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4252 - accuracy: 0.8653 - val_loss: 0.3435 - val_accuracy: 0.8611\n",
            "Epoch 111/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8542 - val_loss: 0.3717 - val_accuracy: 0.8556\n",
            "Epoch 112/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.8625 - val_loss: 0.4038 - val_accuracy: 0.8611\n",
            "Epoch 113/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8625 - val_loss: 0.4976 - val_accuracy: 0.8500\n",
            "Epoch 114/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.8250 - val_loss: 0.3852 - val_accuracy: 0.8722\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7acfa6998610>"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_class = [round(x[0]) for x in y_pred]\n",
        "\n",
        "print(accuracy_score(y_pred_class, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkpWWijTW2qD",
        "outputId": "638e27fe-c6de-4a8f-d915-9e48a3173b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step\n",
            "0.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nvTSeZqhZsoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "kjasht_6mEKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.drop('Class', axis = 1).to_numpy()\n",
        "\n",
        "y = train_df['Class']\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "y_1 = encoder.fit_transform(y)\n",
        "X_1 = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "loXGOT3Llmwi"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_2 = X_1.reshape((X.shape[0], X.shape[1], 1))"
      ],
      "metadata": {
        "id": "rqHbZtPXlmwj"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_2,y_1, test_size =0.2 , random_state= 42)"
      ],
      "metadata": {
        "id": "CgQq0BIOlmwj"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7q5kYoNlj9cA"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=32, callbacks = es)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Swo6HnYljyN",
        "outputId": "0b669782-bc53-4a5e-f20b-6c9efb52983c"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "23/23 [==============================] - 5s 60ms/step - loss: 1.2195 - accuracy: 0.5028 - val_loss: 0.7970 - val_accuracy: 0.4778\n",
            "Epoch 2/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7609 - accuracy: 0.4181 - val_loss: 0.7342 - val_accuracy: 0.3389\n",
            "Epoch 3/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7162 - accuracy: 0.4792 - val_loss: 0.6886 - val_accuracy: 0.5167\n",
            "Epoch 4/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.5889 - val_loss: 0.6258 - val_accuracy: 0.6167\n",
            "Epoch 5/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.6431 - val_loss: 0.6062 - val_accuracy: 0.6833\n",
            "Epoch 6/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5965 - accuracy: 0.7125 - val_loss: 0.5438 - val_accuracy: 0.8056\n",
            "Epoch 7/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5589 - accuracy: 0.7431 - val_loss: 0.5176 - val_accuracy: 0.8278\n",
            "Epoch 8/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7039 - accuracy: 0.5917 - val_loss: 0.6641 - val_accuracy: 0.5000\n",
            "Epoch 9/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5731 - accuracy: 0.6944 - val_loss: 0.5265 - val_accuracy: 0.7944\n",
            "Epoch 10/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7944 - val_loss: 0.4850 - val_accuracy: 0.8444\n",
            "Epoch 11/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4956 - accuracy: 0.8000 - val_loss: 0.4481 - val_accuracy: 0.8611\n",
            "Epoch 12/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.8125 - val_loss: 0.4080 - val_accuracy: 0.8556\n",
            "Epoch 13/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4893 - accuracy: 0.8361 - val_loss: 0.4105 - val_accuracy: 0.8500\n",
            "Epoch 14/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.8139 - val_loss: 0.3761 - val_accuracy: 0.8667\n",
            "Epoch 15/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.8333 - val_loss: 0.3957 - val_accuracy: 0.8389\n",
            "Epoch 16/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.8208 - val_loss: 0.3597 - val_accuracy: 0.8556\n",
            "Epoch 17/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5480 - accuracy: 0.8250 - val_loss: 0.5651 - val_accuracy: 0.7611\n",
            "Epoch 18/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.8153 - val_loss: 0.3521 - val_accuracy: 0.8611\n",
            "Epoch 19/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.8111 - val_loss: 0.3608 - val_accuracy: 0.8556\n",
            "Epoch 20/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.8375 - val_loss: 0.3585 - val_accuracy: 0.8667\n",
            "Epoch 21/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.8417 - val_loss: 0.4043 - val_accuracy: 0.8500\n",
            "Epoch 22/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.8403 - val_loss: 0.3534 - val_accuracy: 0.8667\n",
            "Epoch 23/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.8472 - val_loss: 0.3437 - val_accuracy: 0.8778\n",
            "Epoch 24/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8486 - val_loss: 0.3430 - val_accuracy: 0.8722\n",
            "Epoch 25/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.8528 - val_loss: 0.3450 - val_accuracy: 0.8556\n",
            "Epoch 26/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.8486 - val_loss: 0.3475 - val_accuracy: 0.8722\n",
            "Epoch 27/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8583 - val_loss: 0.3430 - val_accuracy: 0.8722\n",
            "Epoch 28/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.8417 - val_loss: 0.3590 - val_accuracy: 0.8222\n",
            "Epoch 29/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.8542 - val_loss: 0.3526 - val_accuracy: 0.8722\n",
            "Epoch 30/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3928 - accuracy: 0.8528 - val_loss: 0.3410 - val_accuracy: 0.8722\n",
            "Epoch 31/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.5413 - accuracy: 0.8458 - val_loss: 0.3415 - val_accuracy: 0.8722\n",
            "Epoch 32/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8333 - val_loss: 0.3378 - val_accuracy: 0.8722\n",
            "Epoch 33/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8403 - val_loss: 0.3361 - val_accuracy: 0.8722\n",
            "Epoch 34/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4750 - accuracy: 0.8639 - val_loss: 0.3368 - val_accuracy: 0.8722\n",
            "Epoch 35/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.8653 - val_loss: 0.3465 - val_accuracy: 0.8722\n",
            "Epoch 36/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.8542 - val_loss: 0.4391 - val_accuracy: 0.8444\n",
            "Epoch 37/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.8500 - val_loss: 0.3575 - val_accuracy: 0.8667\n",
            "Epoch 38/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.8514 - val_loss: 0.3462 - val_accuracy: 0.8667\n",
            "Epoch 39/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8542 - val_loss: 0.3387 - val_accuracy: 0.8667\n",
            "Epoch 40/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8597 - val_loss: 0.4615 - val_accuracy: 0.8389\n",
            "Epoch 41/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.8542 - val_loss: 0.3671 - val_accuracy: 0.8667\n",
            "Epoch 42/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.5182 - accuracy: 0.5472 - val_loss: 0.6456 - val_accuracy: 0.5278\n",
            "Epoch 43/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6144 - accuracy: 0.6917 - val_loss: 0.5403 - val_accuracy: 0.8389\n",
            "Epoch 44/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.7611 - val_loss: 0.4828 - val_accuracy: 0.8444\n",
            "Epoch 45/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7792 - val_loss: 0.4344 - val_accuracy: 0.8500\n",
            "Epoch 46/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.4423 - val_accuracy: 0.8167\n",
            "Epoch 47/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7722 - val_loss: 0.4445 - val_accuracy: 0.8500\n",
            "Epoch 48/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.8181 - val_loss: 0.3978 - val_accuracy: 0.8667\n",
            "Epoch 49/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8306 - val_loss: 0.3686 - val_accuracy: 0.8778\n",
            "Epoch 50/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.8444 - val_loss: 0.3558 - val_accuracy: 0.8722\n",
            "Epoch 51/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8333 - val_loss: 0.3561 - val_accuracy: 0.8722\n",
            "Epoch 52/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.8486 - val_loss: 0.3521 - val_accuracy: 0.8667\n",
            "Epoch 53/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.8458 - val_loss: 0.3450 - val_accuracy: 0.8778\n",
            "Epoch 54/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4954 - accuracy: 0.8403 - val_loss: 0.3527 - val_accuracy: 0.8333\n",
            "Epoch 55/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.8653 - val_loss: 0.3552 - val_accuracy: 0.8722\n",
            "Epoch 56/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.8556 - val_loss: 0.3630 - val_accuracy: 0.8722\n",
            "Epoch 57/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.8528 - val_loss: 0.3444 - val_accuracy: 0.8833\n",
            "Epoch 58/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.8514 - val_loss: 0.3587 - val_accuracy: 0.8722\n",
            "Epoch 59/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8486 - val_loss: 0.3408 - val_accuracy: 0.8667\n",
            "Epoch 60/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.8597 - val_loss: 0.4549 - val_accuracy: 0.8556\n",
            "Epoch 61/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.8375 - val_loss: 0.3720 - val_accuracy: 0.8833\n",
            "Epoch 62/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4434 - accuracy: 0.8542 - val_loss: 0.3493 - val_accuracy: 0.8667\n",
            "Epoch 63/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.8569 - val_loss: 0.3451 - val_accuracy: 0.8833\n",
            "Epoch 64/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.8528 - val_loss: 0.3710 - val_accuracy: 0.8111\n",
            "Epoch 65/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4330 - accuracy: 0.8333 - val_loss: 0.4114 - val_accuracy: 0.8111\n",
            "Epoch 66/150\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4401 - accuracy: 0.8264 - val_loss: 0.4398 - val_accuracy: 0.8611\n",
            "Epoch 67/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.8375 - val_loss: 0.3994 - val_accuracy: 0.8833\n",
            "Epoch 68/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4335 - accuracy: 0.8528 - val_loss: 0.3851 - val_accuracy: 0.8778\n",
            "Epoch 69/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8556 - val_loss: 0.3791 - val_accuracy: 0.8667\n",
            "Epoch 70/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8361 - val_loss: 0.3749 - val_accuracy: 0.8722\n",
            "Epoch 71/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4663 - accuracy: 0.8444 - val_loss: 0.3641 - val_accuracy: 0.8833\n",
            "Epoch 72/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4402 - accuracy: 0.8458 - val_loss: 0.3619 - val_accuracy: 0.8722\n",
            "Epoch 73/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4399 - accuracy: 0.8486 - val_loss: 0.3637 - val_accuracy: 0.8667\n",
            "Epoch 74/150\n",
            "23/23 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.8375 - val_loss: 0.3511 - val_accuracy: 0.8722\n",
            "Epoch 75/150\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 0.4594 - accuracy: 0.8514 - val_loss: 0.3462 - val_accuracy: 0.8778\n",
            "Epoch 76/150\n",
            "23/23 [==============================] - 0s 9ms/step - loss: 0.4523 - accuracy: 0.8569 - val_loss: 0.4164 - val_accuracy: 0.8389\n",
            "Epoch 77/150\n",
            "23/23 [==============================] - 0s 11ms/step - loss: 0.4315 - accuracy: 0.8083 - val_loss: 0.3853 - val_accuracy: 0.8667\n",
            "Epoch 78/150\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.8417 - val_loss: 0.3643 - val_accuracy: 0.8389\n",
            "Epoch 79/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8556 - val_loss: 0.3572 - val_accuracy: 0.8722\n",
            "Epoch 80/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8653 - val_loss: 0.3427 - val_accuracy: 0.8667\n",
            "Epoch 81/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4151 - accuracy: 0.8569 - val_loss: 0.3467 - val_accuracy: 0.8444\n",
            "Epoch 82/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.8500 - val_loss: 0.3576 - val_accuracy: 0.8667\n",
            "Epoch 83/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8569 - val_loss: 0.3495 - val_accuracy: 0.8722\n",
            "Epoch 84/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8542 - val_loss: 0.3617 - val_accuracy: 0.8722\n",
            "Epoch 85/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8639 - val_loss: 0.3694 - val_accuracy: 0.8722\n",
            "Epoch 86/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7972 - val_loss: 0.4673 - val_accuracy: 0.8000\n",
            "Epoch 87/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.8264 - val_loss: 0.3701 - val_accuracy: 0.8333\n",
            "Epoch 88/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8458 - val_loss: 0.3520 - val_accuracy: 0.8667\n",
            "Epoch 89/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8653 - val_loss: 0.3585 - val_accuracy: 0.8722\n",
            "Epoch 90/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4116 - accuracy: 0.8653 - val_loss: 0.3449 - val_accuracy: 0.8667\n",
            "Epoch 91/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.6917 - val_loss: 0.9635 - val_accuracy: 0.4944\n",
            "Epoch 92/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8537 - accuracy: 0.5097 - val_loss: 0.7430 - val_accuracy: 0.4944\n",
            "Epoch 93/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.6582 - accuracy: 0.5319 - val_loss: 0.5992 - val_accuracy: 0.5667\n",
            "Epoch 94/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5528 - accuracy: 0.6167 - val_loss: 0.5151 - val_accuracy: 0.6889\n",
            "Epoch 95/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7556 - val_loss: 0.4603 - val_accuracy: 0.8222\n",
            "Epoch 96/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.8167 - val_loss: 0.4204 - val_accuracy: 0.8611\n",
            "Epoch 97/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.8472 - val_loss: 0.4288 - val_accuracy: 0.8500\n",
            "Epoch 98/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8292 - val_loss: 0.4182 - val_accuracy: 0.8611\n",
            "Epoch 99/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4301 - accuracy: 0.8444 - val_loss: 0.3806 - val_accuracy: 0.8667\n",
            "Epoch 100/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8611 - val_loss: 0.3623 - val_accuracy: 0.8667\n",
            "Epoch 101/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8667 - val_loss: 0.3514 - val_accuracy: 0.8667\n",
            "Epoch 102/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8569 - val_loss: 0.3416 - val_accuracy: 0.8611\n",
            "Epoch 103/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4730 - accuracy: 0.8486 - val_loss: 0.3444 - val_accuracy: 0.8667\n",
            "Epoch 104/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8556 - val_loss: 0.3507 - val_accuracy: 0.8611\n",
            "Epoch 105/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8597 - val_loss: 0.3445 - val_accuracy: 0.8611\n",
            "Epoch 106/150\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8569 - val_loss: 0.3409 - val_accuracy: 0.8611\n",
            "Epoch 107/150\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.8694 - val_loss: 0.3449 - val_accuracy: 0.8722\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7acf7d6c2950>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_class = [round(x[0]) for x in y_pred]\n",
        "\n",
        "print(accuracy_score(y_pred_class, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj0iyUnrl04o",
        "outputId": "73e2853d-150c-4ab3-b6f5-bebb47fc7c19"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step\n",
            "0.8722222222222222\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "kjasht_6mEKl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}